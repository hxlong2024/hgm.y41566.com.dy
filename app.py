import streamlit as st
import os
import time
import re
import sqlite3
import asyncio
import httpx
import requests
import random
import string
from datetime import datetime
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.core.os_manager import ChromeType

# ==========================================
# 0. æ•°æ®åº“ç®¡ç†æ¨¡å—
# ==========================================
class DatabaseManager:
    def __init__(self, db_name="resource_cache.db"):
        self.conn = sqlite3.connect(db_name, check_same_thread=False)
        self.create_table()

    def create_table(self):
        cursor = self.conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS shares (
                original_url TEXT PRIMARY KEY,
                my_share_url TEXT,
                title TEXT,
                platform TEXT,
                created_at TIMESTAMP
            )
        ''')
        self.conn.commit()

    def get_share(self, original_url):
        cursor = self.conn.cursor()
        cursor.execute("SELECT my_share_url FROM shares WHERE original_url = ?", (original_url,))
        result = cursor.fetchone()
        return result[0] if result else None

    def add_share(self, original_url, my_share_url, title, platform):
        cursor = self.conn.cursor()
        try:
            cursor.execute(
                "INSERT OR REPLACE INTO shares (original_url, my_share_url, title, platform, created_at) VALUES (?, ?, ?, ?, ?)",
                (original_url, my_share_url, title, platform, datetime.now())
            )
            self.conn.commit()
        except Exception as e:
            print(f"å†™å…¥å¤±è´¥: {e}")

db = DatabaseManager()

# ==========================================
# 1. å¤¸å…‹å¼•æ“
# ==========================================
class SimpleQuarkEngine:
    def __init__(self, cookies):
        self.headers = {
            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'cookie': cookies,
            'origin': 'https://pan.quark.cn',
            'referer': 'https://pan.quark.cn/',
        }
    
    def _params(self):
        return {'pr': 'ucpro', 'fr': 'pc', '__dt': random.randint(100, 9999), '__t': int(time.time() * 1000)}

    async def save_and_share(self, share_url, title):
        try:
            if '/s/' not in share_url: return False, "é“¾æ¥æ ¼å¼é”™è¯¯", None
            pwd_id = share_url.split('/s/')[-1].split('?')[0]
            
            async with httpx.AsyncClient(headers=self.headers) as client:
                r = await client.post("https://drive-pc.quark.cn/1/clouddrive/share/sharepage/token",
                                      json={"pwd_id": pwd_id, "passcode": ""}, params=self._params())
                stoken = r.json().get('data', {}).get('stoken')
                if not stoken: return False, "Cookieæ— æ•ˆæˆ–èµ„æºå¤±æ•ˆ", None

                params = self._params()
                params.update({"pwd_id": pwd_id, "stoken": stoken, "pdir_fid": "0"})
                r = await client.get("https://drive-pc.quark.cn/1/clouddrive/share/sharepage/detail", params=params)
                items = r.json().get('data', {}).get('list', [])
                if not items: return False, "å†…å®¹ä¸ºç©º", None
                
                source_fids = [i['fid'] for i in items]
                source_tokens = [i['share_fid_token'] for i in items]
                file_name = items[0]['file_name']

                save_data = {"fid_list": source_fids, "fid_token_list": source_tokens, "to_pdir_fid": "0", "pwd_id": pwd_id, "stoken": stoken, "scene": "link"}
                r = await client.post("https://drive.quark.cn/1/clouddrive/share/sharepage/save", json=save_data, params=self._params())
                if r.json().get('code') not in [0, 'OK']: return False, f"è½¬å­˜å¤±è´¥: {r.json().get('message')}", None
                
                await asyncio.sleep(1.5)
                list_params = self._params()
                list_params.update({'pdir_fid': '0', '_page': 1, '_size': 20, '_sort': 'updated_at:desc'})
                r = await client.get('https://drive-pc.quark.cn/1/clouddrive/file/sort', params=list_params)
                
                new_fid = None
                for item in r.json().get('data', {}).get('list', []):
                    if item['file_name'] == file_name:
                        new_fid = item['fid']
                        break
                if not new_fid:
                    if r.json().get('data', {}).get('list'): new_fid = r.json()['data']['list'][0]['fid']
                    else: return False, "æ‰¾ä¸åˆ°è½¬å­˜æ–‡ä»¶", None

                share_data = {"fid_list": [new_fid], "title": f"Share: {title}", "url_type": 1, "expired_type": 1}
                r = await client.post("https://drive-pc.quark.cn/1/clouddrive/share", json=share_data, params=self._params())
                share_res = r.json()
                
                if share_res.get('code') in [0, 'OK']: return True, "æˆåŠŸ", share_res['data']['share_url']
                else: return False, f"åˆ†äº«å¤±è´¥: {share_res.get('message')}", None

        except Exception as e: return False, f"å¼‚å¸¸: {str(e)}", None

# ==========================================
# 2. ç™¾åº¦å¼•æ“
# ==========================================
class AdvancedBaiduEngine:
    def __init__(self, cookies):
        self.s = requests.Session()
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36',
            'Referer': 'https://pan.baidu.com',
            'Cookie': cookies
        }
        self.bdstoken = ''

    def init_token(self):
        try:
            r = self.s.get('https://pan.baidu.com/api/gettemplatevariable', params={'fields': '["bdstoken"]'}, headers=self.headers)
            if r.json().get('errno') == 0:
                self.bdstoken = r.json()['result']['bdstoken']
                return True
            return False
        except: return False

    def save_and_share(self, share_url, pwd, title):
        try:
            if not self.bdstoken and not self.init_token(): return False, "Cookieå¤±æ•ˆ", None
            m = re.search(r'baidu\.com/s/1([\w\-]+)', share_url) or re.search(r'baidu\.com/s/([\w\-]+)', share_url)
            if not m: return False, "é“¾æ¥é”™è¯¯", None
            surl = m.group(1)

            verify_params = {'surl': surl, 't': int(time.time() * 1000), 'bdstoken': self.bdstoken, 'channel': 'chunlei', 'web': 1, 'clienttype': 0}
            r = self.s.post('https://pan.baidu.com/share/verify', params=verify_params, data={'pwd': pwd, 'vcode': '', 'vcode_str': ''}, headers=self.headers)
            res_json = r.json()
            if res_json['errno'] != 0: return False, "éªŒè¯å¤±è´¥", None
            self.headers['Cookie'] += f"; BDCLND={res_json.get('randsk')}"

            page_content = self.s.get(share_url.split('?')[0], headers=self.headers).text
            try:
                shareid = re.search(r'"shareid":(\d+?),', page_content).group(1)
                uk = re.search(r'"share_uk":"(\d+?)",', page_content).group(1)
                fs_ids = re.findall(r'"fs_id":\s*(\d+)', page_content)
                fs_ids = list(set(fs_ids))
                if not fs_ids: return False, "æ— æ–‡ä»¶", None
                fs_id_list_str = f"[{','.join(fs_ids)}]"
            except: return False, "é¡µé¢è§£æå¤±è´¥", None

            transfer_params = {'shareid': shareid, 'from': uk, 'bdstoken': self.bdstoken}
            r = self.s.post('https://pan.baidu.com/share/transfer', params=transfer_params, data={'fsidlist': fs_id_list_str, 'path': '/'}, headers=self.headers)
            if r.json().get('errno') != 0: return False, "è½¬å­˜å¤±è´¥", None

            list_res = self.s.get('https://pan.baidu.com/api/list', params={'dir': '/', 'bdstoken': self.bdstoken, 'order': 'time', 'desc': 1}, headers=self.headers).json()
            new_fs_id = list_res['list'][0]['fs_id'] if list_res.get('list') else None
            if not new_fs_id: return False, "æ‰¾ä¸åˆ°æ–°æ–‡ä»¶", None

            new_pwd = ''.join(random.choices(string.ascii_letters + string.digits, k=4))
            share_res = self.s.post('https://pan.baidu.com/share/set', params={'bdstoken': self.bdstoken, 'channel': 'chunlei', 'clienttype': 0, 'web': 1}, data={'period': 0, 'pwd': new_pwd, 'fid_list': f'[{new_fs_id}]', 'schannel': 4}, headers=self.headers).json()

            if share_res.get('errno') == 0: return True, "æˆåŠŸ", f"{share_res['link']}?pwd={new_pwd}"
            else: return False, "åˆ†äº«å¤±è´¥", None
        except Exception as e: return False, f"å¼‚å¸¸: {str(e)}", None

# ==========================================
# 3. çˆ¬è™«éƒ¨åˆ†
# ==========================================
st.set_page_config(page_title="èµ„æºåˆ†å‘å¹³å°", page_icon="ğŸš€", layout="wide")
st.title("ğŸš€ èµ„æºæœç´¢ & è‡ªåŠ¨åˆ†å‘ç³»ç»Ÿ")

with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
    quark_cookie = st.text_area("â˜ï¸ å¤¸å…‹ Cookie", placeholder="å¡«å…¥ cookie...", height=100)
    baidu_cookie = st.text_area("ğŸ» ç™¾åº¦ Cookie", placeholder="å¡«å…¥ cookie...", height=100)
    st.divider()
    st.caption("âœ… çŠ¶æ€ä¿å­˜å·²å¯ç”¨ (ä¿®å¤æŒ‰é’®å¤±æ•ˆ)")

def get_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (iPhone; CPU iPhone OS 13_2_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.3 Mobile/15E148 Safari/604.1")
    chrome_options.add_argument("--window-size=375,812")
    prefs = {"profile.managed_default_content_settings.images": 2}
    chrome_options.add_experimental_option("prefs", prefs)
    chrome_options.page_load_strategy = 'eager'
    return webdriver.Chrome(service=Service(ChromeDriverManager(chrome_type=ChromeType.CHROMIUM).install()), options=chrome_options)

def extract_pwd(text_context):
    match = re.search(r'æå–ç \s*[:ï¼š]\s*([a-zA-Z0-9]{4})', text_context)
    if match: return match.group(1)
    return None

def scrape_data(keyword):
    driver = None
    try:
        driver = get_driver()
        url = "http://hgm.y41566.com/app/index.html?id=test"
        driver.get(url)
        wait = WebDriverWait(driver, 10)
        search_input = wait.until(EC.element_to_be_clickable((By.ID, "search")))
        search_input.clear()
        search_input.send_keys(keyword)
        btn = driver.find_element(By.ID, "submitSearch")
        driver.execute_script("arguments[0].click();", btn)
        try:
            wait.until(EC.presence_of_element_located((By.CLASS_NAME, "info")))
            time.sleep(0.5)
        except: return []
        
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        results = []
        all_infos = soup.find_all("div", class_="info")
        
        for info_div in all_infos:
            parent_box = info_div.parent
            title = ""
            title_tag = parent_box.find(class_="js-title")
            if title_tag: title = title_tag.get_text(strip=True)
            if not title:
                for text in info_div.stripped_strings:
                    if "é“¾æ¥" not in text and "æå–ç " not in text and len(text) > 1:
                        title = text.strip('"').strip()
                        break
            if not title: title = "æœªçŸ¥èµ„æº"
            
            baidu_data = None
            quark_data = None
            visible_text = info_div.get_text(separator=" ", strip=True)
            copy_btn = info_div.find("button", class_="js-copy")
            clipboard_text = copy_btn.get("data-clipboard-text", "") if copy_btn else ""
            full_text_context = visible_text + " " + clipboard_text
            all_links = re.findall(r'(https?://(?:pan\.baidu\.com|pan\.quark\.cn|pan\.xunlei\.com)[^\s"<>]+)', full_text_context)
            pwd = extract_pwd(full_text_context)

            for link in all_links:
                if "baidu.com" in link:
                    final_url = link
                    if pwd and "pwd=" not in link:
                        connector = "&" if "?" in link else "?"
                        final_url = f"{link}{connector}pwd={pwd}"
                    baidu_data = {"url": final_url, "pwd": pwd}
                elif "quark.cn" in link:
                    quark_data = {"url": link} 
            
            if baidu_data or quark_data:
                results.append({"title": title, "baidu": baidu_data, "quark": quark_data})
        return results
    except Exception as e:
        st.error(f"æœç´¢å‡ºé”™: {e}")
        return []
    finally:
        if driver: driver.quit()

# ==========================================
# 4. ç»Ÿä¸€å¤„ç†å‡½æ•°
# ==========================================
def handle_universal_save(original_url, title, platform, pwd=None):
    cached_link = db.get_share(original_url)
    if cached_link:
        st.toast(f"âš¡ï¸ {platform} å‘½ä¸­ç¼“å­˜ï¼", icon="ğŸš€")
        return cached_link
    
    success, msg, new_link = False, "", None
    if platform == "quark":
        if not quark_cookie:
            st.error("è¯·å…ˆé…ç½®å¤¸å…‹ Cookie")
            return None
        engine = SimpleQuarkEngine(quark_cookie)
        try:
            success, msg, new_link = asyncio.run(engine.save_and_share(original_url, title))
        except Exception as e: msg = str(e)

    elif platform == "baidu":
        if not baidu_cookie:
            st.error("è¯·å…ˆé…ç½®ç™¾åº¦ Cookie")
            return None
        engine = AdvancedBaiduEngine(baidu_cookie)
        try:
            success, msg, new_link = engine.save_and_share(original_url, pwd, title)
        except Exception as e: msg = str(e)
    
    if success:
        db.add_share(original_url, new_link, title, platform)
        st.toast(f"{platform} è½¬å­˜æˆåŠŸï¼", icon="âœ…")
        return new_link
    else:
        st.error(msg)
        return None

# ==========================================
# 5. ä¿®å¤åçš„ä¸»ç•Œé¢é€»è¾‘ (ä½¿ç”¨ Session State)
# ==========================================

# åˆå§‹åŒ– Session State
if 'search_results' not in st.session_state:
    st.session_state['search_results'] = None

col1, col2 = st.columns([4, 1])
with col1:
    query = st.text_input("ğŸ” æœèµ„æº", placeholder="è¾“å…¥ç”µå½±/ç”µè§†å‰§/åŠ¨æ¼«åç§°...", label_visibility="collapsed")
with col2:
    submit = st.button("å…¨ç½‘æœç´¢", type="primary", use_container_width=True)

# æœç´¢é€»è¾‘ï¼šåªè´Ÿè´£æ›´æ–° Session State
if submit and query:
    with st.spinner("ğŸ•·ï¸ çˆ¬è™«æ­£åœ¨æ£€ç´¢..."):
        data = scrape_data(query)
        st.session_state['search_results'] = data # ã€å…³é”®ã€‘ä¿å­˜ç»“æœåˆ° Session State

# æ˜¾ç¤ºé€»è¾‘ï¼šä» Session State è¯»å–æ•°æ®ï¼Œè€Œä¸æ˜¯ä¾èµ– submit æŒ‰é’®çŠ¶æ€
if st.session_state['search_results']:
    data = st.session_state['search_results']
    st.success(f"âœ… æ‰¾åˆ° {len(data)} ä¸ªèµ„æº")
    
    for idx, item in enumerate(data):
        with st.container(border=True):
            st.markdown(f"#### ğŸ¬ {item['title']}")
            c1, c2 = st.columns(2)
            
            # --- ç™¾åº¦ç½‘ç›˜ ---
            with c1:
                if item['baidu']:
                    b_url = item['baidu']['url']
                    b_pwd = item['baidu']['pwd'] or ""
                    
                    st.caption("ğŸ» ç™¾åº¦ç½‘ç›˜")
                    # ä½¿ç”¨å”¯ä¸€çš„ key
                    if st.button("âš¡ è·å–ä¸‹è½½é“¾æ¥", key=f"get_b_{idx}", type="secondary", use_container_width=True):
                        with st.spinner("æ­£åœ¨è½¬å­˜..."):
                            final_link = handle_universal_save(b_url, item['title'], "baidu", b_pwd)
                            if final_link:
                                # ã€å…³é”®ã€‘æŠŠç”Ÿæˆçš„é“¾æ¥ä¹Ÿå­˜å…¥ Session State
                                st.session_state[f"link_b_{idx}"] = final_link
                    
                    # æ£€æŸ¥ Session State æ˜¯å¦æœ‰è¯¥é“¾æ¥
                    if f"link_b_{idx}" in st.session_state:
                        my_link = st.session_state[f"link_b_{idx}"]
                        st.markdown(f"""<div style="margin-top:5px;padding:8px;background:#fef2f2;border:1px solid #fecaca;border-radius:4px;">
                        <a href="{my_link}" target="_blank" style="color:#dc2626;font-weight:bold;text-decoration:none">ğŸ‘‰ ç‚¹å‡»ä¸‹è½½ (ç™¾åº¦)</a>
                        </div>""", unsafe_allow_html=True)
                else:
                    st.caption("ğŸ» æ— ç™¾åº¦èµ„æº")
            
            # --- å¤¸å…‹ç½‘ç›˜ ---
            with c2:
                if item['quark']:
                    q_url = item['quark']['url']
                    
                    st.caption("â˜ï¸ å¤¸å…‹ç½‘ç›˜")
                    if st.button("âš¡ è·å–ä¸‹è½½é“¾æ¥", key=f"get_q_{idx}", type="primary", use_container_width=True):
                        with st.spinner("æ­£åœ¨è½¬å­˜..."):
                            final_link = handle_universal_save(q_url, item['title'], "quark")
                            if final_link:
                                st.session_state[f"link_q_{idx}"] = final_link
                    
                    if f"link_q_{idx}" in st.session_state:
                        my_link = st.session_state[f"link_q_{idx}"]
                        st.markdown(f"""<div style="margin-top:5px;padding:8px;background:#f0f9ff;border:1px solid #bae6fd;border-radius:4px;">
                        <a href="{my_link}" target="_blank" style="color:#0284c7;font-weight:bold;text-decoration:none">ğŸ‘‰ ç‚¹å‡»ä¸‹è½½ (å¤¸å…‹)</a>
                        </div>""", unsafe_allow_html=True)
                else:
                    st.caption("â˜ï¸ æ— å¤¸å…‹èµ„æº")

elif submit:
    st.toast("è¯·è¾“å…¥æœç´¢å…³é”®è¯")
